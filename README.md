Through this work, we are trying to answer the following question:
Can the integration of state-of-the-art monolingual, multilingual, and cross-lingual semantic role labeling (SRL) technique that uses Bi-LSTM models for fine-tuning the BERT and XLM-R like models enhance translational accuracy in low-resource languages?
